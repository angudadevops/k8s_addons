kind: Namespace
apiVersion: v1
metadata:
  name: logging
---
kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: zookeeper-1
  namespace: logging
spec:
  replicas: 1
  serviceName: zookeeper
  selector:
    matchLabels:
      app: zookeeper-1
      name: zookeeper-1
  template:
    metadata:
      labels:
        app: zookeeper-1
        name: zookeeper-1
    spec:
      containers:
      - name: zookeeper-1
        image: digitalwonderland/zookeeper
        ports:
        - containerPort: 2181
        env:
        - name: ZOOKEEPER_ID
          value: "1"
        - name: ZOOKEEPER_SERVER_1
          value: zookeeper-1
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper-1
  namespace: logging
  labels:
    app: zookeeper-1
spec:
  ports:
  - name: client
    port: 2181
    protocol: TCP
  - name: follower
    port: 2888
    protocol: TCP
  - name: leader
    port: 3888
    protocol: TCP
  selector:
    app: zookeeper-1
---
kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: kafka-broker
  namespace: logging
spec:
  replicas: 1
  serviceName: kafka
  selector:
    matchLabels:
      name: kafka
  template:
    metadata:
      labels:
        name: kafka
        app: kafka
    spec:
      containers:
      - name: kafka
        image: wurstmeister/kafka
        ports:
        - containerPort: 9092
        env:
        - name: KAFKA_ADVERTISED_PORT
          value: "9092"
        - name: KAFKA_ADVERTISED_HOST_NAME
          valueFrom:
             fieldRef:
               fieldPath: status.podIP
        - name: ENABLE_AUTO_EXTEND
          value: "true"
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: zookeeper-1:2181
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: 'false'
        - name: KAFKA_CREATE_TOPICS
          value: kube-logs-fluentbit-stream:2:1
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-service
  namespace: logging
  labels:
    app: kafka
spec:
  ports:
  - port: 9092
    name: kafka-port
    targetPort: 9092
    protocol: TCP
  selector:
    app: kafka
  type: NodePort
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    app: elasticsearch
    k8s-app: elasticsearch-logging
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: "Elasticsearch"
spec:
  selector:
    app: elasticsearch
  ports:
    - port: 9200
      protocol: TCP
      name: db
    - port: 9300
      name: inter-node
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    k8s-app: elasticsearch-logging
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: elasticsearch-logging
  namespace: logging
  labels:
    k8s-app: elasticsearch-logging
    addonmanager.kubernetes.io/mode: Reconcile
rules:
- apiGroups:
  - ""
  resources:
  - "services"
  - "namespaces"
  - "endpoints"
  verbs:
  - "get"
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: elasticsearch
  labels:
    k8s-app: elasticsearch-logging
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
- kind: ServiceAccount
  name: elasticsearch
  namespace: logging
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: elasticsearch-logging
  apiGroup: ""
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    k8s-app: elasticsearch-logging
    version: v7.4.2
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  serviceName: elasticsearch
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
        k8s-app: elasticsearch-logging
    spec:
      serviceAccountName: elasticsearch
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
        imagePullPolicy: Always
        securityContext:
          capabilities:
            add: ["SYS_CHROOT"]
        resources:
            limits:
              cpu: 1500m
              memory: 3Gi
            requests:
              cpu: 100m
              memory: 3Gi
        ports:
        - containerPort: 9200
          name: db
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        livenessProbe:
          tcpSocket:
            port: transport
          initialDelaySeconds: 5
          timeoutSeconds: 10
        readinessProbe:
          tcpSocket:
            port: transport
          initialDelaySeconds: 5
          timeoutSeconds: 10
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
        env:
          - name: "NAMESPACE"
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: cluster.name
            value: kubernetes-logging
          - name: discovery.type
            value: single-node
            # - name: ES_JAVA_OPTS
            #   value: "-Xms512m -Xmx512m"
      volumes:
          - emptyDir:
              medium: ""
            name: elasticsearch-data
      initContainers:
      - name: increase-vm-max-map
        image: registry.opensuse.org/opensuse/busybox:latest
        imagePullPolicy: Always
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluent-bit
  namespace: logging
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: fluent-bit-read
rules:
- apiGroups: [""]
  resources:
  - namespaces
  - pods
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: fluent-bit-read
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluent-bit-read
subjects:
- kind: ServiceAccount
  name: fluent-bit
  namespace: logging
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: logging
  labels:
    k8s-app: fluent-bit
data:
  # Configuration files: server, input, filters and output
  # ======================================================
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    @INCLUDE input-kubernetes.conf
    @INCLUDE filter-kubernetes.conf
    @INCLUDE output-kafka.conf

  input-kubernetes.conf: |
    [INPUT]
        Name              tail
        Tag               kube.*
        Path              /var/log/containers/*.log
        Parser            docker
        DB                /var/log/flb_kube.db
        Mem_Buf_Limit     5MB
        Skip_Long_Lines   On
        Refresh_Interval  10

  filter-kubernetes.conf: |
    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Kube_Tag_Prefix     kube.var.log.containers.
        Merge_Log           On
        Merge_Log_Key       log_processed
        K8S-Logging.Parser  On
        K8S-Logging.Exclude Off

    # ${HOSTNAME} returns the host name.
    # But Fluentbit runs in a container. So, it is not meaningful.
    # Instead, copy the host name from the Kubernetes object.
    [FILTER]
        Name nest
        Match *
        Operation lift
        Nested_under kubernetes
    # Remove offending fields, see: https://github.com/fluent/fluent-bit/issues/1291
    [FILTER]
        Name record_modifier
        Match *
        Remove_key annotations
        Remove_key labels

  output-kafka.conf: |
    [OUTPUT]
        Name           kafka
        Match          *
        Brokers        kafka-service:9092
        Topics         kube-logs-fluentbit-stream
        Timestamp_Key  @timestamp
        Retry_Limit    false
        # hides errors "Receive failed: Disconnected" when kafka kills idle connections
        rdkafka.log.connection.close false
        # producer buffer is not included in http://fluentbit.io/documentation/0.12/configuration/memory_usage.html#estimating
        rdkafka.queue.buffering.max.kbytes 10240
        # for logs you'll probably want this ot be 0 or 1, not more
        rdkafka.request.required.acks 1

  parsers.conf: |
    [PARSER]
        Name        docker
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L
        Time_Keep   On
        # Command      |  Decoder | Field | Optional Action
        # =============|==================|=================
        Decode_Field_As   escaped_utf8    log  do_next
        Decode_Field_As   json       log

    [PARSER]
        Name        syslog
        Format      regex
        Regex       ^\<(?<pri>[0-9]+)\>(?<time>[^ ]* {1,2}[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[a-zA-Z0-9_\/\.\-]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? *(?<message>.*)$
        Time_Key    time
        Time_Format %b %d %H:%M:%S
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluent-bit
  namespace: logging
  labels:
    k8s-app: fluent-bit-logging
    version: v1
    kubernetes.io/cluster-service: "true"
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      k8s-app: fluent-bit-logging
  template:
    metadata:
      labels:
        k8s-app: fluent-bit-logging
        version: v1
        kubernetes.io/cluster-service: "true"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "2020"
        prometheus.io/path: /api/v1/metrics/prometheus
    spec:
      containers:
      - name: fluent-bit
        image: fluent/fluent-bit:1.5
        imagePullPolicy: Always
        ports:
        - containerPort: 2020
        readinessProbe:
          httpGet:
            path: /api/v1/metrics/prometheus
            port: 2020
        livenessProbe:
          httpGet:
            path: /
            port: 2020
        resources:
          requests:
            cpu: 5m
            memory: 10Mi
          limits:
            cpu: 50m
            memory: 60Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: fluent-bit-config
          mountPath: /fluent-bit/etc/
      terminationGracePeriodSeconds: 10
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: fluent-bit-config
        configMap:
          name: fluent-bit-config
      serviceAccountName: fluent-bit
      tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
---
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: logging
  labels:
    app: kibana
spec:
  ports:
  - port: 5601
    nodePort: 31120
  selector:
    app: kibana
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
  labels:
    app: kibana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:7.10.0
        imagePullPolicy: Always
        resources:
          limits:
            cpu: 1000m
          requests:
            cpu: 100m
        env:
          - name: ELASTICSEARCH_URL
            value: http://elasticsearch:9200
        ports:
        - containerPort: 5601
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-kafka-configmap
  namespace: logging
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
  logstash.conf: |
    # all input will come from filebeat, no local logs
    input {
      kafka {
        bootstrap_servers => [ "${KAFKA_HOSTS}" ]
        topics => [ "${KAFKA_TOPICS}" ]
        codec => plain
      }
    }
    filter {
      mutate { gsub => [ "message", "@timestamp", "_@timestamp"] }
      if [message] =~ "^\{.*\}*$" {
           json {source => "message"}
      }
      date {
          match => [ "_@timestamp", "UNIX" ]
          remove_field => "_@timestamp"
          remove_tag => "_timestampparsefailure"
      }
      mutate {
        remove_field => ["message", "time", "@version", "stream", "log_processed"]
      }
    }
    output {
      elasticsearch {
        index => "logstash-kafka-%{+YYYY.MM.dd}"
        hosts => [ "${ES_HOSTS}" ]
      }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: logstash-kafka
  name: logstash-kafka
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: logstash-kafka
  template:
    metadata:
      labels:
        app: logstash-kafka
    spec:
      containers:
      - image: docker.elastic.co/logstash/logstash:7.10.0
        name: logstash-kafka
        ports:
        - containerPort: 25826
        - containerPort: 5044
        - containerPort: 8080
        env:
        - name: ES_HOSTS
          value: "elasticsearch:9200"
        - name: KAFKA_HOSTS
          value: "kafka-service:9092"
        - name: KAFKA_TOPICS
          value: "kube-logs-fluentbit-stream"
        resources: {}
        volumeMounts:
        - name: logstash-pipeline-volume
          mountPath: /usr/share/logstash/pipeline
      volumes:
      - name: logstash-pipeline-volume
        configMap:
          name: logstash-kafka-configmap
          items:
          - key: logstash.conf
            path: logstash.conf
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: logstash-kafka
  name: logstash-kafka
  namespace: logging
spec:
  ports:
  - name: "25826"
    port: 25826
    targetPort: 25826
  - name: "5044"
    port: 5044
    targetPort: 5044
  - name: "8080"
    port: 8080
    targetPort: 8080
  selector:
    app: logstash-kafka
